{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\py\\envs\\tf-keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import random as rn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras.layers import AvgPool2D, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adadelta, RMSprop, Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "y= data.iloc[:,0] \n",
    "\n",
    "data= data.drop(\"label\", axis=1)\n",
    "\n",
    "x= data\n",
    "\n",
    "#standardize my data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(x)\n",
    "\n",
    "#split into training and tessting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust data\n",
    "import scipy.misc as smp\n",
    "\n",
    "\n",
    "for x in X_train:\n",
    "    for n, i in enumerate(x):\n",
    "        if i > 0:\n",
    "            x[n] = 0\n",
    "        else:\n",
    "            x[n] = 1\n",
    "\n",
    "for x in X_test:\n",
    "    for n, i in enumerate(x):\n",
    "        if i > 0:\n",
    "            x[n] = 0\n",
    "        else:\n",
    "            x[n] = 1\n",
    "# B= np.reshape(X_train[90], (-1, 28))\n",
    "# data = B\n",
    "\n",
    "# img = smp.toimage( data )       # Create a PIL image\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #adjust data\n",
    "# import scipy.misc as smp\n",
    "\n",
    "\n",
    "# for x in data.values:\n",
    "#     for n, i in enumerate(x):\n",
    "#         if i > 0:\n",
    "#             x[n] = 0\n",
    "#         else:\n",
    "#             x[n] = 1\n",
    "# # B= np.reshape(X_train[90], (-1, 28))\n",
    "# # data = B\n",
    "\n",
    "# # img = smp.toimage( data )       # Create a PIL image\n",
    "# # img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "X_train = X_train.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Keras CNN Model\n",
    "# model = tf.keras.models.Sequential()\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(32, (3,3), padding = \"same\", activation = \"relu\", input_shape = X_train.shape[1:]))\n",
    "# model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(64, (3,3), padding = \"same\", activation = \"relu\"))\n",
    "# model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# model.add(tf.keras.layers.Conv2D(128, (3,3), padding = \"same\", activation = \"relu\"))\n",
    "# model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = X_train.shape[1:]))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 886,282\n",
      "Trainable params: 886,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) # loss = \"categorical_crossentropy\",\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "29400/29400 [==============================] - 319s 11ms/step - loss: 0.3690 - acc: 0.8773\n",
      "Epoch 2/27\n",
      "29400/29400 [==============================] - 322s 11ms/step - loss: 0.1002 - acc: 0.9694\n",
      "Epoch 3/27\n",
      "29400/29400 [==============================] - 334s 11ms/step - loss: 0.0758 - acc: 0.9777\n",
      "Epoch 4/27\n",
      "29400/29400 [==============================] - 347s 12ms/step - loss: 0.0565 - acc: 0.9826\n",
      "Epoch 5/27\n",
      "29400/29400 [==============================] - 389s 13ms/step - loss: 0.0496 - acc: 0.9835\n",
      "Epoch 6/27\n",
      "29400/29400 [==============================] - 381s 13ms/step - loss: 0.0422 - acc: 0.9864\n",
      "Epoch 7/27\n",
      "29400/29400 [==============================] - 381s 13ms/step - loss: 0.0394 - acc: 0.9882\n",
      "Epoch 8/27\n",
      "29400/29400 [==============================] - 362s 12ms/step - loss: 0.0374 - acc: 0.9879\n",
      "Epoch 9/27\n",
      "29400/29400 [==============================] - 344s 12ms/step - loss: 0.0347 - acc: 0.9895\n",
      "Epoch 10/27\n",
      "29400/29400 [==============================] - 349s 12ms/step - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 11/27\n",
      "29400/29400 [==============================] - 355s 12ms/step - loss: 0.0272 - acc: 0.9911\n",
      "Epoch 12/27\n",
      "29400/29400 [==============================] - 343s 12ms/step - loss: 0.0269 - acc: 0.9918\n",
      "Epoch 13/27\n",
      "29400/29400 [==============================] - 368s 13ms/step - loss: 0.0259 - acc: 0.9918\n",
      "Epoch 14/27\n",
      "29400/29400 [==============================] - 406s 14ms/step - loss: 0.0227 - acc: 0.9923\n",
      "Epoch 15/27\n",
      "29400/29400 [==============================] - 423s 14ms/step - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 16/27\n",
      "29400/29400 [==============================] - 460s 16ms/step - loss: 0.0209 - acc: 0.9933\n",
      "Epoch 17/27\n",
      "29400/29400 [==============================] - 445s 15ms/step - loss: 0.0195 - acc: 0.9941\n",
      "Epoch 18/27\n",
      "29400/29400 [==============================] - 448s 15ms/step - loss: 0.0181 - acc: 0.9943\n",
      "Epoch 19/27\n",
      "29400/29400 [==============================] - 461s 16ms/step - loss: 0.0191 - acc: 0.9936\n",
      "Epoch 20/27\n",
      "29400/29400 [==============================] - 462s 16ms/step - loss: 0.0150 - acc: 0.9948\n",
      "Epoch 21/27\n",
      "29400/29400 [==============================] - 471s 16ms/step - loss: 0.0191 - acc: 0.9939\n",
      "Epoch 22/27\n",
      "29400/29400 [==============================] - 46012s 2s/step - loss: 0.0178 - acc: 0.9949\n",
      "Epoch 23/27\n",
      "29400/29400 [==============================] - 392s 13ms/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 24/27\n",
      "29400/29400 [==============================] - 397s 13ms/step - loss: 0.0145 - acc: 0.9955\n",
      "Epoch 25/27\n",
      "29400/29400 [==============================] - 409s 14ms/step - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 26/27\n",
      "29400/29400 [==============================] - 407s 14ms/step - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 27/27\n",
      "29400/29400 [==============================] - 359s 12ms/step - loss: 0.0154 - acc: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa04b123dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=27, batch_size=86)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600/12600 [==============================] - 54s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9896031746031746"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test) \n",
    "\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([y, data], axis=1)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, svm, neighbors, tree, discriminant_analysis, model_selection\n",
    "\n",
    "# MLA = [\n",
    "#   #  Ensemble Methods\n",
    "#     ensemble.AdaBoostClassifier(),\n",
    "#     ensemble.BaggingClassifier(),\n",
    "#     ensemble.ExtraTreesClassifier(),\n",
    "#     ensemble.GradientBoostingClassifier(),\n",
    "#     ensemble.RandomForestClassifier(),\n",
    "\n",
    "#   #  Gaussian Processes\n",
    "#     gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "#     #GLM\n",
    "#     linear_model.LogisticRegressionCV(),\n",
    "#     linear_model.PassiveAggressiveClassifier(),\n",
    "#     linear_model.RidgeClassifierCV(),\n",
    "#     linear_model.SGDClassifier(),\n",
    "#     linear_model.Perceptron(),\n",
    "    \n",
    "#     #Navies Bayes\n",
    "#     naive_bayes.BernoulliNB(),\n",
    "#     naive_bayes.GaussianNB(),\n",
    "    \n",
    "#     #Nearest Neighbor\n",
    "#     neighbors.KNeighborsClassifier(),\n",
    "#         #SVM\n",
    "#     svm.SVC(probability=True),\n",
    "#     svm.NuSVC(probability=True),\n",
    "#     svm.LinearSVC(),\n",
    "    \n",
    "#     #Trees    \n",
    "#     tree.DecisionTreeClassifier(),\n",
    "#     tree.ExtraTreeClassifier(),\n",
    "    \n",
    "#     #Discriminant Analysis\n",
    "#     discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "#     discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "# #     #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "# #     XGBClassifier()    \n",
    "#     ]\n",
    "\n",
    "\n",
    "\n",
    "# #split dataset in cross-validation with this splitter class:\n",
    "# cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .33, train_size = .66, random_state = 0 ) \n",
    "\n",
    "# #create table to compare MLA metrics\n",
    "# MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "# MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# #create table to compare MLA predictions\n",
    "# MLA_predict = data.iloc[:,0]\n",
    "\n",
    "# #index through MLA and save performance to table\n",
    "# row_index = 0\n",
    "# for alg in MLA:\n",
    "\n",
    "#     #set name and parameters\n",
    "#     MLA_name = alg.__class__.__name__\n",
    "#     MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "#     MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "#     #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "#     cv_results = model_selection.cross_validate(alg, data.iloc[:,1:], data.iloc[:,0], cv  = cv_split)\n",
    "\n",
    "#     MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "#     MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "#     MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "#     #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "#     MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "#     #save MLA predictions - see section 6 for usage\n",
    "#     alg.fit(data.iloc[:,1:], data.iloc[:,0])\n",
    "#     MLA_predict[MLA_name] = alg.predict(data.iloc[:,1:])\n",
    "#     row_index+=1\n",
    "\n",
    "    \n",
    "# #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "# MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "# MLA_compare\n",
    "# #MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "# MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "# MLA_compare\n",
    "# #MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()\n",
    "\n",
    "x= test\n",
    "\n",
    "#standardize my data\n",
    "sc = StandardScaler()\n",
    "test = sc.fit_transform(x)\n",
    "\n",
    "for x in test:\n",
    "    for n, i in enumerate(x):\n",
    "        if i > 0:\n",
    "            x[n] = 0\n",
    "        else:\n",
    "            x[n] = 1\n",
    "\n",
    "#reshape\n",
    "test = test.reshape(-1,28,28,1)\n",
    "\n",
    "test_pred = model.predict(test)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['ImageId'] = range(1, (len(test)+1))\n",
    "submission['Label'] = np.argmax(test_pred, axis=1)\n",
    "\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
